{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from mnist import MNIST\n",
    "import math\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mndata = MNIST('MNIST')\n",
    "X_test, Y_test = mndata.load_testing()\n",
    "X_train, Y_train = mndata.load_training()\n",
    "\n",
    "X_test = np.array(list(map(lambda x: np.array(x), X_test))).T\n",
    "Y_test = np.array(Y_test).T\n",
    "\n",
    "X_train = np.array(list(map(lambda x: np.array(x), X_train))).T\n",
    "Y_train = np.array(Y_train).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "IMAGE_WIDTH = 28\n",
    "INPUTS_NUMBER = IMAGE_WIDTH*IMAGE_WIDTH\n",
    "CLASSES_NUMBER = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Normalize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def normalize_data(X_train, X_test):\n",
    "    total = np.concatenate((X_train, X_test), axis=1)\n",
    "    avg = np.mean(total, axis=1, keepdims=True)\n",
    "    norm = np.linalg.norm(total, axis=1, keepdims=True)\n",
    "    norm = np.array([np.apply_along_axis(lambda x: x if x != 0 else 1, arr=norm, axis=1)]).T\n",
    "    X_train_normalized = (X_train - avg)/norm\n",
    "    X_test_normalized = (X_test - avg)/norm\n",
    "    return X_train_normalized, X_test_normalized\n",
    "\n",
    "X_train_normalized, X_test_normalized = normalize_data(X_train, X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X_train = X_train_normalized\n",
    "X_test = X_test_normalized"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot labels encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10, 60000)\n",
      "(10, 10000)\n"
     ]
    }
   ],
   "source": [
    "def one_hot(labels):\n",
    "    onehot = np.zeros((CLASSES_NUMBER, len(labels)))\n",
    "    for i in range(len(labels)):\n",
    "        onehot[int(labels[i]),i] = 1\n",
    "    return onehot\n",
    "\n",
    "Y_train_onehot = one_hot(Y_train)\n",
    "Y_test_onehot = one_hot(Y_test)\n",
    "\n",
    "print(Y_train_onehot.shape)\n",
    "print(Y_test_onehot.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y_train = Y_train_onehot\n",
    "Y_test = Y_test_onehot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(784, 60000)\n",
      "(10, 60000)\n",
      "(784, 10000)\n",
      "(10, 10000)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape)\n",
    "print(Y_train.shape)\n",
    "print(X_test.shape)\n",
    "print(Y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def plot_image(record):\n",
    "    plt.imshow(record.reshape(IMAGE_WIDTH,-1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# NN Implementation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 383,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def initialize_parameters(layers_dims):\n",
    "    np.random.seed(3)\n",
    "    parameters = []\n",
    "    for i in range(1,len(layers_dims)):\n",
    "        layer_params = {}\n",
    "        layer_params['W'] = tf.Variable(tf.random_normal([layers_dims[i], layers_dims[i-1]]), name='W'+str(i), dtype=tf.float32)\n",
    "        layer_params['b'] = tf.Variable(tf.zeros((layers_dims[i], 1), dtype=tf.float32), name='b'+str(i))\n",
    "        parameters.append(layer_params)\n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 384,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'W': <tf.Variable 'W1_46:0' shape=(5, 4) dtype=float32_ref>,\n",
       "  'b': <tf.Variable 'b1_46:0' shape=(5, 1) dtype=float32_ref>},\n",
       " {'W': <tf.Variable 'W2_27:0' shape=(6, 5) dtype=float32_ref>,\n",
       "  'b': <tf.Variable 'b2_27:0' shape=(6, 1) dtype=float32_ref>}]"
      ]
     },
     "execution_count": 384,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "initialize_parameters([4,5,6])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Forward Propagation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def linear_forward(A, W, b):\n",
    "    Z = tf.matmul(W, A) + b\n",
    "    return Z\n",
    "\n",
    "\n",
    "def linear_activation_forward(A_prev, W, b):\n",
    "    Z = linear_forward(A_prev, W, b)\n",
    "    A = tf.nn.relu(Z)        \n",
    "    return A\n",
    "\n",
    "\n",
    "def model(dim, X):\n",
    "    \n",
    "    parameters = initialize_parameters(dim)\n",
    "    \n",
    "    L = len(parameters)\n",
    "    A = X\n",
    "    \n",
    "    for i in range(L-1):\n",
    "        W = parameters[i]['W']\n",
    "        b = parameters[i]['b']\n",
    "        A = linear_activation_forward(A, W, b)\n",
    "    W = parameters[L-1]['W']\n",
    "    b = parameters[L-1]['b']\n",
    "    A = linear_forward(A, W, b)\n",
    "    \n",
    "    return A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-2.20228713e-05]\n",
      " [-1.27018650e-04]\n",
      " [ 2.34575856e-04]\n",
      " [-1.07710890e-04]]\n"
     ]
    }
   ],
   "source": [
    "X = tf.placeholder(tf.float64, [2, None], name='X')\n",
    "mod = model([2,3,4], X)\n",
    "with tf.Session() as sess:\n",
    "    sess.run(tf.global_variables_initializer())\n",
    "    print(sess.run(mod, feed_dict={X: [[1],[2]]}))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def batch(index, size, X, Y):\n",
    "    begin = index*size\n",
    "    end = index*size+size\n",
    "    end = end if end < X.shape[1] else X.shape[1] - 1\n",
    "    return X[:, begin: end], Y[:, begin: end]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 408,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train(dim, X_train, Y_train, X_test, Y_test, epochs=20, batch_size=256, learning_rate=0.01):\n",
    "    \n",
    "    Y_ = tf.placeholder(tf.float32, [CLASSES_NUMBER, None], name='X')\n",
    "    X_ = tf.placeholder(tf.float32, [INPUTS_NUMBER, None], name='Y')\n",
    "    \n",
    "    logits = model([INPUTS_NUMBER, 256, 256, CLASSES_NUMBER], X_)\n",
    "    cost_function = tf.reduce_mean(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y_, dim=0))\n",
    "    train_step = tf.train.AdamOptimizer(learning_rate).minimize(cost_function)\n",
    "    num_batches = int(math.ceil(X_train.shape[1]/batch_size))\n",
    "    with tf.Session() as sess:\n",
    "        sess.run(tf.global_variables_initializer())\n",
    "        for epoch in range(epochs):\n",
    "            for i in range(num_batches):\n",
    "                batch_x, batch_y = batch(i, batch_size, X_train, Y_train)\n",
    "                _, cost = sess.run([train_step, cost_function], feed_dict={X_: batch_x, Y_: batch_y})\n",
    "            print(\"cost: \", cost)\n",
    "        pred = tf.nn.softmax(logits, dim=0)\n",
    "        correct_prediction = tf.equal(tf.argmax(pred, 0), tf.argmax(Y_, 0))\n",
    "        accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))\n",
    "        print(\"Train accuracy: \", accuracy.eval(feed_dict={X_: X_train, Y_: Y_train}))\n",
    "        print(\"Test accuracy: \", accuracy.eval(feed_dict={X_: X_test, Y_: Y_test}))\n",
    "        return logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "cost:  1.5864121\n",
      "cost:  0.2537342\n",
      "cost:  0.05990955\n",
      "cost:  0.13145597\n",
      "cost:  0.09205328\n",
      "cost:  0.016188107\n",
      "cost:  0.013966052\n",
      "cost:  0.03234447\n",
      "cost:  0.12525138\n",
      "cost:  0.008042746\n",
      "cost:  0.0011373047\n",
      "cost:  0.004378619\n",
      "cost:  0.006593442\n",
      "cost:  3.4753199\n"
     ]
    }
   ],
   "source": [
    "Y_ = tf.placeholder(tf.float32, [CLASSES_NUMBER, None])\n",
    "X_ = tf.placeholder(tf.float32, [INPUTS_NUMBER, None])\n",
    "trained = train([INPUTS_NUMBER, 256, 256, CLASSES_NUMBER], X_train, Y_train, X_test, Y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred = tf.nn.softmax(logits, dim=0)\n",
    "correct_prediction = tf.equal(tf.argmax(pred, 0), tf.argmax(Y_, 0))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7226167\n",
      "0.7278\n"
     ]
    }
   ],
   "source": [
    "# print(logits.eval(feed_dict={X_: X_train, Y_: Y_train}).shape)\n",
    "# print(tf.nn.softmax_cross_entropy_with_logits(logits=logits, labels=Y_, dim=0).eval(feed_dict={X_: X_train, Y_: Y_train}).shape)\n",
    "# lin\n",
    "print(accuracy.eval(feed_dict={X_: X_train, Y_: Y_train}))\n",
    "print(accuracy.eval(feed_dict={X_: X_test, Y_: Y_test}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
