{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "import numpy\n",
    "import matplotlib.pyplot as plt\n",
    "import mnist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: './train-labels-idx1-ubyte'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-16-5e9b9ced1801>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtrain\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmnist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mMNIST\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_testing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mnist/loader.py\u001b[0m in \u001b[0;36mload_training\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    124\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload_training\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    125\u001b[0m         ims, labels = self.load(os.path.join(self.path, self.train_img_fname),\n\u001b[0;32m--> 126\u001b[0;31m                                 os.path.join(self.path, self.train_lbl_fname))\n\u001b[0m\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain_images\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mprocess_images\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mnist/loader.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(self, path_img, path_lbl)\u001b[0m\n\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_lbl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 197\u001b[0;31m         \u001b[0;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopener\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_lbl\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'rb'\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    198\u001b[0m             \u001b[0mmagic\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\">II\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m8\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    199\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mmagic\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m2049\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Frameworks/Python.framework/Versions/3.6/lib/python3.6/site-packages/mnist/loader.py\u001b[0m in \u001b[0;36mopener\u001b[0;34m(self, path_fn, *args, **kwargs)\u001b[0m\n\u001b[1;32m    192\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mgzip\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_fn\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m'.gz'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    193\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 194\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpath_fn\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    195\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    196\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_img\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpath_lbl\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './train-labels-idx1-ubyte'"
     ]
    }
   ],
   "source": [
    "train = mnist.MNIST().load_training()\n",
    "test = mnist.MNIST.load_testing()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "display() missing 1 required positional argument: 'img'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-b14c6b389eb2>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisplay\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: display() missing 1 required positional argument: 'img'"
     ]
    }
   ],
   "source": [
    "data.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def sigmoid(z):\n",
    "    res = 1./(1.+np.exp(-z))\n",
    "    return (res, z)\n",
    "\n",
    "def relu(z):\n",
    "    return (np.maximum(0, z), z)\n",
    "    \n",
    "    \n",
    "def sigmoid_backward(dA, cache):\n",
    "    Z = cache\n",
    "    A = sigmoid(Z)[0]\n",
    "    dx = dA*(A*(1-A))\n",
    "    return dx\n",
    "    \n",
    "\n",
    "def relu_backward(dA, cache):\n",
    "    z = cache\n",
    "    dz = np.array(dA, copy=True)\n",
    "    dz[z <= 0] = 0\n",
    "    return dz\n",
    "\n",
    "\n",
    "def initialize_parameters(layers_dims):\n",
    "    np.random.seed(3)\n",
    "    parameters = []\n",
    "    for i in range(1,len(layers_dims)):\n",
    "        layer_params = {}\n",
    "        layer_params['W'] = np.random.randn(layers_dims[i], layers_dims[i-1])*0.01\n",
    "        layer_params['b'] = np.zeros((layers_dims[i], 1))\n",
    "        parameters.append(layer_params)\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def compute_cost(AL, Y):\n",
    "    m = Y.shape[1]\n",
    "    cost = -np.sum(np.multiply(Y, np.log(AL))+np.multiply((1-Y),np.log(1-AL)))/m\n",
    "    \n",
    "    cost = np.squeeze(cost) \n",
    "    assert(cost.shape == ())\n",
    "    \n",
    "    return cost\n",
    "\n",
    "\n",
    "def linear(cache):\n",
    "    A, W, b = cache\n",
    "    return np.dot(W, A) + b\n",
    "\n",
    "\n",
    "def linear_forward(A, W, b, threads=1):\n",
    "    n_n = W.shape[0]\n",
    "    Z = None\n",
    "    if threads > 1 and n_n > 1:\n",
    "        threshold = int(n_n/threads)\n",
    "        segments = []\n",
    "        for i in range(threads):\n",
    "            W_segment = W[i*threshold:(i+1)*threshold,:]\n",
    "            b_segment = b[i*threshold:(i+1)*threshold,:]\n",
    "            segments.append((A, W_segment, b_segment))\n",
    "            \n",
    "        segmentsZ = foreach(linear, segments, threads=threads, return_=True)\n",
    "        Z = segmentsZ[0]\n",
    "        for i in range(1, len(segmentsZ)):\n",
    "            Z = np.append(Z, segmentsZ[i], axis=0)\n",
    "    else:\n",
    "        Z = np.dot(W, A) + b\n",
    "    assert(Z.shape == (W.shape[0], A.shape[1]))\n",
    "    cache = (A, W, b)\n",
    "    return Z, cache\n",
    "\n",
    "\n",
    "def linear_activation_forward(A_prev, W, b, activation, threads=1):\n",
    "    if activation == \"sigmoid\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = sigmoid(Z)\n",
    "        \n",
    "    elif activation == \"relu\":\n",
    "        Z, linear_cache = linear_forward(A_prev, W, b)\n",
    "        A, activation_cache = relu(Z)\n",
    "        \n",
    "    assert (A.shape == (W.shape[0], A_prev.shape[1]))\n",
    "    cache = (linear_cache, activation_cache)\n",
    "    return A, cache\n",
    "\n",
    "\n",
    "def forward_prop(parameters, X, threads=1):\n",
    "    \n",
    "    L = len(parameters)\n",
    "    A = X\n",
    "    caches = []\n",
    "    \n",
    "    for i in range(L-1):\n",
    "        W = parameters[i]['W']\n",
    "        b = parameters[i]['b']\n",
    "        A, cache = linear_activation_forward(A, W, b, 'relu', threads)\n",
    "        caches.append(cache)\n",
    "        \n",
    "    W = parameters[L-1]['W']\n",
    "    b = parameters[L-1]['b']\n",
    "    A, cache = linear_activation_forward(A, W, b, 'sigmoid', threads)\n",
    "    caches.append(cache)\n",
    "    \n",
    "    return A, caches    \n",
    "\n",
    "\n",
    "def linear_backward(dZ, cache):\n",
    "    A_prev, W, b = cache\n",
    "    m = A_prev.shape[1]\n",
    "    dW = np.dot(dZ, A_prev.T)/m\n",
    "    db = np.sum(dZ, axis=1, keepdims=True)/m\n",
    "    dA_prev = np.dot(W.T, dZ)\n",
    "    \n",
    "    assert (dA_prev.shape == A_prev.shape)\n",
    "    assert (dW.shape == W.shape)\n",
    "    assert (db.shape == b.shape)\n",
    "    \n",
    "    return dA_prev, dW, db\n",
    "\n",
    "\n",
    "def linear_activation_backward(dA, cache, activation):\n",
    "\n",
    "    linear_cache, activation_cache = cache\n",
    "    if activation == \"relu\":\n",
    "        dZ = relu_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "        \n",
    "    elif activation == \"sigmoid\":\n",
    "        dZ = sigmoid_backward(dA, activation_cache)\n",
    "        dA_prev, dW, db = linear_backward(dZ, linear_cache)\n",
    "    \n",
    "    return dA_prev, dW, db\n",
    "\n",
    "\n",
    "def backward_prop(dAL, caches):\n",
    "    L = len(caches)\n",
    "    dA = dAL\n",
    "    grads = []\n",
    "    dA, dW, db = linear_activation_backward(dA, caches[L-1], 'sigmoid')\n",
    "    layer_grads = {'dW': dW, 'db': db}\n",
    "    grads.append(layer_grads)\n",
    "    for i in reversed(range(0, L-1)):\n",
    "        dA, dW, db = linear_activation_backward(dA, caches[i], 'relu')\n",
    "        layer_grads = {'dW': dW, 'db': db}\n",
    "        grads.append(layer_grads)\n",
    "    grads.reverse()\n",
    "    return grads\n",
    "\n",
    "\n",
    "def update_parameters(parameters, grads, learning_rate):\n",
    "    for i in range(len(parameters)):\n",
    "        parameters[i]['W'] = parameters[i]['W'] - grads[i]['dW']*learning_rate\n",
    "        parameters[i]['b'] = parameters[i]['b'] - grads[i]['db']*learning_rate\n",
    "    return parameters\n",
    "\n",
    "\n",
    "def predict(parameters, X):\n",
    "    probs = forward_prop(parameters=parameters, X=X)[0]\n",
    "    return (probs > 0.5).astype(int)\n",
    "\n",
    " \n",
    "def L_layer_model(X_train, Y_train, X_test, Y_test, layers_dims, num_iterations=2000, learning_rate=0.005, threads = 1):\n",
    "    np.random.seed(1)\n",
    "    layers_dims.insert(0, X_train.shape[0])\n",
    "    parameters = initialize_parameters(layers_dims=layers_dims)\n",
    "    costs = []\n",
    "    iterations = []\n",
    "    for i in range(num_iterations):\n",
    "        AL, caches = forward_prop(parameters=parameters, X=X_train, threads=threads)\n",
    "        # Cost function. Inputs: \"A2, Y, parameters\". Outputs: \"cost\".\n",
    "        cost = compute_cost(AL=AL, Y=Y_train)\n",
    "        # Backpropagation. Inputs: \"parameters, cache, X, Y\". Outputs: \"grads\".\n",
    "        dAL = -(np.divide(Y_train, AL) - np.divide(1 - Y_train, 1 - AL))\n",
    "        grads = backward_prop(dAL, caches)\n",
    "        \n",
    "        # Gradient descent parameter update. Inputs: \"parameters, grads\". Outputs: \"parameters\".\n",
    "        parameters = update_parameters(grads=grads, learning_rate=learning_rate, parameters=parameters)\n",
    "        # Print the cost every 100 iterations\n",
    "        if i % 100 == 0:\n",
    "            iterations.append(i)\n",
    "            costs.append(cost)\n",
    "            print(\"Cost after iteration %i: %f\" %(i, cost))\n",
    "            \n",
    "    Y_prediction_test = predict(parameters,X=X_test)\n",
    "    Y_prediction_train = predict(parameters,X=X_train)\n",
    "    print(\"train accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_train - Y_train)) * 100))\n",
    "    print(\"test accuracy: {} %\".format(100 - np.mean(np.abs(Y_prediction_test - Y_test)) * 100))\n",
    "    plt.plot(iterations, costs)\n",
    "    plt.show()\n",
    "    \n",
    "    return parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
